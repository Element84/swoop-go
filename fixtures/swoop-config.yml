handlers:
  argoHandler:
    type: argoWorkflowHandler
    #serverUrl: https://kubernetes:6443
    #token: {secrets.argo_token}

  cirrusHandler:
    type: cirrusWorkflowHandler
    #sqsUrl: https://sqs.aws.com/0142354653636::sqs::queue

  noopHandler:
    type: noop
    parameters:
      workflowUuid:
        type: string
        format: uuid

  # We believe it is best to re-template the request
  # (at least with regard to secrets) JIT for every request execution
  publishS3Handler:
    type: httpHandler
    url: https://{secrets.minio-user}:{secrets.minio-password}@our-minio:9000
    requestBody: |
      {
        "fixed": "a_value",
        "name": "{{ .parameters.workflowName -}}",
        "date": "{{ .parameters.feature.properties.datetime -}}"
      }
    operation: POST
    secrets:
      # simplest approach for secret renewal is to have a ttl
      # and periodically re-resolve the secret values, but does mean
      # invalid secrets may be used for some time until the ttl expires
      #
      # how to handle secrets that need to resolve a token,
      # have some other initialization step, or are of some built-in
      # limited duration?
      - name: user
        type: file
        path: /secrets-mount/username-secret
        ttl: 1200
    headers:
      Authorization: "Basic {{ .secrets.user }} {{ .secrets.password}}"
      Content-Type: "application/json"
      X-Workflow-Name: "{{ .parameters.workflowName }}"
    backoff:
      retries: 10
      seconds: 5
      factor: 2
      max: 25
    errors:
      - status: 400
        retryable: false
      - status: 400
        message: ".*timed out.*"
        retryable: true
    parameters:
      workflowName:
        type: string
        default: a_value
      feature:
        type: object

conductors:
  instance-a:
    handlers:
      - argoHandler
      - publishS3Handler

callbacks:
  publishS3Push: &callbacksPublishS3Push
    handler: publishS3Handler
    type: perFeature
    when:
      - "successful"
    featureFilter: "@.id =~ 'fake*' & @.properties.gsd <= 0"
    parameters:
      workflowName:
        path: .input.features[0].id
      feature:
        value: { "feature": true }
    enabled: true

workflows:
  mirror:
    description: "A workflow to copy STAC items into a local mirror"
    version: 2
    handler: argoHandler
    argoTemplate: workflowtemplate/mirror-workflow
    cacheKeyHashIncludes:
      - .features[].id
      - .features[].collection
    cacheKeyHashExcludes: []
    callbacks:
      publishS3Push:
        <<: *callbacksPublishS3Push
      failed:
        handler: noopHandler
        type: single
        when:
          - "!successful"
        parameters:
          workflowUuid:
            path: .workflow.uuid
  cirrus-example:
    callbacks:
      publishS3Push:
        <<: *callbacksPublishS3Push
        when:
          - "!failed"
          - "successful"
    title: "Cirrus example workflow"
    description: "An example workflow config for a cirrus workflow"
    version: 1
    handler: cirrusHandler
    sfnArn: arn:aws:states:us-west-2:09876543210:stateMachine:cirrus-example
    cacheKeyHashIncludes:
      - .features[].id
      - .features[].collection
    cacheKeyHashExcludes: []
    links:
      - href: https://example.com/repo
        rel: external
        type: text/html
        title: "source repository"
      - href: https://example.com/docs
        rel: external
        type: text/html
        title: "process documentation"
